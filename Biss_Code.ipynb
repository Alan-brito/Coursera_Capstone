{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Getting the webpage content of Wikipedia\n",
    "wikipedia = requests.get(\"https://en.wikipedia.org/wiki/NE_postcode_area\").content\n",
    "\n",
    "# 2. Converting the HTML content to a BeautifulSoup object\n",
    "wikipedia_soup = BeautifulSoup(wikipedia, \"html.parser\")\n",
    "\n",
    "# 3. Assigning the table content from Wikipedia to variable\n",
    "neighborhoods = wikipedia_soup.table\n",
    "\n",
    "# 4. Converting the tags to lists\n",
    "neighborhoods_lists = []\n",
    "for tag in neighborhoods.find_all(\"tr\"):\n",
    "    temp_list = []\n",
    "    temp_split = tag.text.split(\"\\n\")\n",
    "    for i in range(len(temp_split)):\n",
    "        if i in [1, 3, 5]:\n",
    "            temp_list.append(temp_split[i])\n",
    "    neighborhoods_lists.append(temp_list)\n",
    "\n",
    "# 5. Removing the \"non-geographic\" Local authority area\n",
    "neighborhoods_rows = []\n",
    "for lst in neighborhoods_lists:\n",
    "    if \"non-geographic\" in lst[1]:\n",
    "        continue\n",
    "    else:\n",
    "        lst[2] = re.sub(\" /\", \",\", lst[2])\n",
    "        neighborhoods_rows.append(lst)\n",
    "\n",
    "# 6. Converting the lists into a NumPy array and separates the columns from the values\n",
    "neighborhoods_rows = np.array(neighborhoods_rows)\n",
    "neighborhoods_columns = neighborhoods_rows[0,:]\n",
    "neighborhoods_values = neighborhoods_rows[1:,:]\n",
    "\n",
    "# 7. Creating a DataFrame of the neighborhoods in Newcastle\n",
    "neighborhoods_df = pd.DataFrame(\n",
    "    neighborhoods_values,\n",
    "    columns = neighborhoods_columns\n",
    ").rename(columns={\"Postcode district\": \"PostalCode\"}).sort_values(by=[\"PostalCode\"])\n",
    "\n",
    "# 8. Printing the number of rows in the DataFrame\n",
    "print(\"This DataFrame contains {} rows.\".format(neighborhoods_df.shape[0]))\n",
    "\n",
    "neighborhoods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Loading the coordinates csv into notebook\n",
    "coordinates_df = pd.read_csv(\"Files/Geospatial_Coordinates.csv\").rename(columns={\"Postcode district\": \"PostalCode\"})\n",
    "\n",
    "# 2. Merging neighborhoods_df with coordinates_df\n",
    "neighborhoods_df = pd.merge(neighborhoods_df, coordinates_df)\n",
    "\n",
    "neighborhoods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# 1. Defining Foursquare credentials and version\n",
    "CLIENT_ID = \"ITYEMLDDKSZTIRSHWI2SXOPCGFJ3AWQY5JKF3PZVKD5EJLIP\"\n",
    "CLIENT_SECRET = \"MFSJZJIIEGJPW2H1TLX1ZEKPACYPWS3KRIOK3HNO3ARJIBQM\"\n",
    "VERSION = \"20200504\"\n",
    "radius = 500\n",
    "limit = 100\n",
    "\n",
    "# 2. Setting the neighborhood's coordinates\n",
    "neighborhood_name = neighborhoods_df.loc[0, \"Neighborhood\"]\n",
    "neighborhood_latitude = neighborhoods_df.loc[0, \"Latitude\"]\n",
    "neighborhood_longitude = neighborhoods_df.loc[0, \"Longitude\"]\n",
    "\n",
    "# 3. Creating URL and sends the GET request\n",
    "url = \"https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}\".format(\n",
    "    CLIENT_ID,\n",
    "    CLIENT_SECRET,\n",
    "    VERSION,\n",
    "    neighborhood_latitude,\n",
    "    neighborhood_longitude,\n",
    "    radius,\n",
    "    limit\n",
    ")\n",
    "results = requests.get(url).json()\n",
    "\n",
    "# 4. Getting the items in JSON\n",
    "venues = results[\"response\"][\"groups\"][0][\"items\"]\n",
    "\n",
    "# 5. Converting JSON into a DataFrame\n",
    "venues_df = json_normalize(venues)\n",
    "\n",
    "# 6. Filtering the columns\n",
    "filtered_columns = [\"venue.name\", \"venue.categories\", \"venue.location.lat\", \"venue.location.lng\"]\n",
    "venues_df = venues_df.loc[:, filtered_columns]\n",
    "\n",
    "# 7. Returning the value of the name key in venue.categories\n",
    "venues_df[\"category\"] = venues_df[\"venue.categories\"].apply(lambda x: x[0][\"name\"])\n",
    "\n",
    "# 8. Renaming the columns\n",
    "venues_df.columns = [x.split(\".\")[-1] for x in venues_df.columns]\n",
    "\n",
    "# 9. Printing the number of venues returned by Foursquare\n",
    "print(\"{} venues were returned by Foursquare.\".format(venues_df.shape[0]))\n",
    "\n",
    "# 10. Adding the neighborhood to each row\n",
    "venues_df[\"neighborhood\"] = neighborhood_name\n",
    "\n",
    "# 11. Setting neighborhood as first column\n",
    "venues_df = venues_df[[\"neighborhood\", \"name\", \"category\", \"lat\", \"lng\"]]\n",
    "\n",
    "venues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Assinging necessary column values to variables\n",
    "neighborhood_values = neighborhoods_df[\"Neighborhood\"].values\n",
    "latitude_values = neighborhoods_df[\"Latitude\"].values\n",
    "longitude_values = neighborhoods_df[\"Longitude\"].values\n",
    "\n",
    "# 2. Sends the GET results for each neighborhood in the DataFrame and appends its JSON in all_venues\n",
    "all_results = []\n",
    "all_venues_neighborhoods = []\n",
    "for hood, lat, lng in zip(neighborhood_values, latitude_values, longitude_values):\n",
    "    \n",
    "    # 2.1. Generates the URL\n",
    "    temp_url = \"https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit{}\".format(CLIENT_ID, CLIENT_SECRET, VERSION, lat, lng, radius, limit)\n",
    "    \n",
    "    # 2.2. Sends the GET request\n",
    "    temp_results = requests.get(temp_url).json()[\"response\"][\"groups\"][0][\"items\"]\n",
    "    \n",
    "    # 2.3. Appends the results to all_venues\n",
    "    all_results.append(temp_results)\n",
    "    \n",
    "    # 2.4. Generates a temporary DataFrame in order to get the number of rows\n",
    "    temp_df = json_normalize(temp_results)\n",
    "    \n",
    "    # 2.5. Appends the neighborhood of each row in the temporary DataFrame\n",
    "    for i in range(temp_df.shape[0]):\n",
    "        all_venues_neighborhoods.append(hood)\n",
    "\n",
    "print(\"Number of results: {}\".format(len(all_results)))\n",
    "print(\"Number of venues: {}\".format(len(all_venues_neighborhoods)))\n",
    "\n",
    "# 3. Converting each JSON into a DataFrame and appends it to all_venues_df\n",
    "all_venues_df = pd.DataFrame()\n",
    "for result in all_results:\n",
    "    all_venues_df = all_venues_df.append(json_normalize(result), sort=False)\n",
    "\n",
    "# 4. Formatting the DataFrame\n",
    "all_venues_df[\"Category\"] = all_venues_df[\"venue.categories\"].apply(lambda x: x[0][\"name\"])\n",
    "all_venues_df[\"Neighborhood\"] = all_venues_neighborhoods\n",
    "filtered_columns = [\"Neighborhood\", \"venue.name\", \"Category\", \"venue.location.lat\", \"venue.location.lng\"]\n",
    "all_venues_df = all_venues_df.loc[:, filtered_columns].reset_index(drop=True)\n",
    "all_venues_df.columns = [\"Neighborhood\", \"Venue\", \"Venue Category\", \"Venue Latitude\", \"Venue Longitude\"]\n",
    "\n",
    "all_venues_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Printing the number of unique venue categories in Ncl neighborhoods\n",
    "print(\"There are {} unique categories\".format(len(all_venues_df[\"Venue Category\"].unique())))\n",
    "\n",
    "# 6. Returning the top 5 neighborhoods with the most venues\n",
    "all_venues_df.groupby(\"Neighborhood\")[\"Venue\"].count().reset_index().sort_values(by=[\"Venue\"], ascending=False).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Splitting the values in Venue Category into dummy variables\n",
    "ncl_dummies = pd.get_dummies(\n",
    "    all_venues_df[\"Venue Category\"],\n",
    "    prefix = \"\",\n",
    "    prefix_sep = \"\"\n",
    ")\n",
    "\n",
    "# 2. Adding neighborhood as first column into dummies DataFrame\n",
    "ncl_dummies[\"neighborhood\"] = all_venues_df[\"Neighborhood\"]\n",
    "fixed_columns = [ncl_dummies.columns[-1]] + list(ncl_dummies.columns[:-1])\n",
    "ncl_dummies = ncl_dummies[fixed_columns]\n",
    "\n",
    "print(ncl_dummies.shape)\n",
    "ncl_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Grouping rows by each neighborhood\n",
    "ncl_grouped = ncl_dummies.groupby(\"neighborhood\").sum().reset_index()\n",
    "\n",
    "# 5. Creating a DataFrame containing the most common venues in each neighborhood\n",
    "ncl_common_venues = pd.DataFrame()\n",
    "for hood in ncl_grouped[\"neighborhood\"]:\n",
    "    temp_df = ncl_grouped[ncl_grouped[\"neighborhood\"] == hood].T.reset_index()\n",
    "    temp_df.columns = [\"Venue\", \"Count\"]\n",
    "    temp_df = temp_df.loc[1:]\n",
    "    temp_df = temp_df[temp_df[\"Count\"] > 0]\n",
    "    temp_df = temp_df.sort_values(by=[\"Count\"], ascending=False).reset_index(drop=True)\n",
    "    temp_df[\"Most Common\"] = [i+1 for i in range(temp_df.shape[0])]\n",
    "    temp_df[\"Neighborhood\"] = hood\n",
    "    temp_df = temp_df[[\"Neighborhood\", \"Most Common\", \"Venue\", \"Count\"]]\n",
    "    ncl_common_venues = ncl_common_venues.append(temp_df)\n",
    "ncl_common_venues.reset_index(drop=True)\n",
    "\n",
    "ncl_common_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Creating a pivot table where each row shows the top 10 most common venues for each neighborhood\n",
    "ncl_common_venues_pivot = ncl_common_venues.pivot(\n",
    "    columns = \"Most Common\",\n",
    "    index = \"Neighborhood\",\n",
    "    values = \"Venue\"\n",
    ").fillna(\"\")\n",
    "\n",
    "ncl_common_venues_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Setting the number of clusters\n",
    "clusters = 4\n",
    "\n",
    "# 2. Dropping the neighborhood column\n",
    "ncl_grouped_clustering = ncl_grouped.drop(\"neighborhood\", axis=1)\n",
    "\n",
    "# 3. Running K-Mean Clustering\n",
    "kmeans = KMeans(n_clusters=clusters, random_state=0).fit(ncl_grouped_clustering)\n",
    "\n",
    "print(kmeans.labels_)\n",
    "\n",
    "# 4. Adding clustering labels to ncl_common_venues_pivot\n",
    "#ncl_common_venues_pivot.insert(0, \"Cluster Labels\", kmeans.labels_)\n",
    "\n",
    "# 5. Merging neighborhoods_df with ncl_common_venues_pivot\n",
    "ncl_common_venues_df = pd.DataFrame(ncl_common_venues_pivot.to_records())\n",
    "ncl_merged = neighborhoods_df.join(ncl_common_venues_df.set_index(\"Neighborhood\"), on=\"Neighborhood\")\n",
    "ncl_merged[\"Cluster Labels\"] = ncl_merged[\"Cluster Labels\"].fillna(4).astype(\"int\")\n",
    "\n",
    "print(ncl_merged.shape[0])\n",
    "ncl_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_venues(dataframe, cluster):\n",
    "    temp_columns = [\"Neighborhood\", \"Cluster Labels\"] + [i for i in dataframe.columns[6:]]\n",
    "    temp_df1 = dataframe[dataframe[\"Cluster Labels\"] == cluster-1][temp_columns]\n",
    "    temp_array = temp_df1.values[:,2:]\n",
    "    temp_list = []\n",
    "    for neighborhood in temp_array:\n",
    "        for venue in neighborhood:\n",
    "            if not venue == \"\":\n",
    "                temp_list.append(venue)\n",
    "    temp_df2 = pd.DataFrame({\n",
    "        \"id\": [i for i in range(len(temp_list))],\n",
    "        \"venue\": temp_list\n",
    "    })\n",
    "    temp_df2 = temp_df2.groupby(\"venue\").id.count().reset_index()\n",
    "    temp_df2 = temp_df2.sort_values(by=\"id\", ascending=False).reset_index(drop=True)\n",
    "    temp_df2 = temp_df2.rename(columns={\n",
    "        \"id\": \"Count\",\n",
    "        \"venue\": \"Venue\"\n",
    "    })\n",
    "    if temp_df1.shape[0] == 1:\n",
    "        print(\"This cluster counts 1 neighborhood.\")\n",
    "    else:\n",
    "        print(\"This cluster counts {} neighborhoods.\".format(temp_df1.shape[0]))\n",
    "    return temp_df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_venues(ncl_merged, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_venues(ncl_merged, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_10_venues(ncl_merged, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
